# üé≠ Acting Clone - Real-time Pose Mirroring System

**Created by: [Shlok Sathe](https://github.com/shloksathe18-dotcom)**  
**Repository: [Acting Clone Project](https://github.com/shloksathe18-dotcom/Acting-Clone-Project-)**

A visually stunning real-time pose tracking application that creates a "clone" or mirror effect of your body movements using advanced computer vision and 3D visualization. Perfect for motion capture, dance practice, fitness tracking, or just having fun with futuristic visual effects!

## ‚ú® Features

- **üéØ Real-time Pose Detection**: Uses Google's MediaPipe for accurate human pose estimation (33 body landmarks)
- **üë• Clone/Mirror Effect**: Creates a horizontally flipped version of your pose in real-time
- **üåà Dynamic Visual Effects**: 
  - Color-changing neon skeletal overlay with HSV color space transitions
  - Pulsing glow effects using sine wave modulation
  - Motion trails that follow joint movements (8-frame history)
  - Gradient color transitions over time
  - Smooth line rendering with dual-layer glow effects
- **üìä Dual Visualization**:
  - 2D camera feed with enhanced visual effects and overlays
  - Real-time 3D pose visualization in a separate matplotlib window
- **‚ö° Performance Optimized**: 
  - FPS monitoring and display
  - Efficient rendering with selective updates
  - Optimized for 30-60 FPS performance

## üõ†Ô∏è Installation & Requirements

### Quick Setup
```bash
pip install opencv-python mediapipe numpy matplotlib
```

### Detailed Dependencies

| Package | Purpose | Version |
|---------|---------|---------|
| `opencv-python` | Camera capture and image processing | >=4.5.0 |
| `mediapipe` | Google's pose estimation solution | >=0.8.0 |
| `numpy` | Numerical computations and array operations | >=1.19.0 |
| `matplotlib` | 3D visualization and plotting | >=3.3.0 |

### System Requirements
- **Camera**: Webcam or external USB camera
- **OS**: Windows 10/11, macOS 10.14+, Linux (Ubuntu 18.04+)
- **Python**: 3.7+ recommended
- **RAM**: 4GB minimum, 8GB recommended
- **CPU**: Multi-core processor for optimal performance

## üöÄ Quick Start

1. **Install Dependencies**
   ```bash
   pip install opencv-python mediapipe numpy matplotlib
   ```

2. **Run the Application**
   ```bash
   python app.py
   ```

3. **Controls & Usage**
   - Stand 3-6 feet from your camera for optimal detection
   - Move around to see the clone effect in real-time
   - Press **'q'** to quit the application
   - Ensure good lighting for better pose detection

4. **Expected Output**
   - **Main Window**: "CLONE TRACKER" showing camera feed with neon effects
   - **3D Window**: Real-time 3D pose visualization with synchronized colors
   - **Console**: Performance metrics and status updates

## üîß How It Works

### 1. üìπ Pose Detection Pipeline
The application uses MediaPipe's pose estimation model to detect **33 key body landmarks** in real-time:

```python
# MediaPipe Pose Landmarks (33 points)
# Face: 0-10 (nose, eyes, ears, mouth)
# Upper Body: 11-16 (shoulders, elbows, wrists)  
# Torso: 11-12, 23-24 (shoulders, hips)
# Lower Body: 23-32 (hips, knees, ankles, feet)
```

**Key Landmarks Include:**
- üé≠ **Face**: Nose, eyes, ears, mouth corners
- üí™ **Upper Body**: Shoulders, elbows, wrists
- ü´Ä **Torso**: Chest, hips connection points
- ü¶µ **Lower Body**: Hips, knees, ankles, feet, toes

### 2. üë• Clone Creation Algorithm
The detected pose is horizontally flipped to create the "clone" effect:

```python
# Mirror transformation - flip X coordinates
clone_landmarks_2d = [
    (int((1 - lm.x) * width), int(lm.y * height)) 
    for lm in results.pose_landmarks.landmark
]

# 3D coordinates also mirrored
clone_landmarks_3d = [
    (1 - lm.x, lm.y, lm.z) 
    for lm in results.pose_landmarks.landmark
]
```

### 3. üé® Visual Effects Engine

#### üåà Color Gradient System
```python
def get_gradient_color(t):
    # HSV to RGB conversion for smooth color transitions
    hue = (t * 120) % 360  # Cycle through color spectrum
    # Convert HSV to RGB with full saturation and brightness
```

**Color Features:**
- **Time-based**: Colors change continuously over time
- **HSV Color Space**: Smooth transitions through color spectrum
- **Pulsing Effect**: Sine wave modulation for breathing effect

#### ‚ú® Neon Glow Effects
```python
def draw_smooth_line(img, pt1, pt2, color, thickness):
    cv2.line(img, pt1, pt2, color, thickness)           # Main line
    cv2.line(img, pt1, pt2, dimmed_color, thickness+2)  # Glow layer

def draw_smooth_circle(img, center, radius, color):
    cv2.circle(img, center, radius, color, -1)          # Outer glow
    cv2.circle(img, center, radius//2, (255,255,255), -1) # White center
```

**Glow Techniques:**
- **Dual-layer Rendering**: Main color + dimmed glow layer
- **Additive Blending**: `cv2.addWeighted()` for realistic glow
- **White Centers**: Bright core for joint markers

#### üåü Motion Trails System
```python
trail_points = []  # Store last 8 frames of joint positions
max_trail_length = 8

# Create fading trail effect
for t_idx, trail_frame in enumerate(trail_points[:-1]):
    trail_alpha = (t_idx / len(trail_points)) * 0.4  # Fade over time
```

**Trail Features:**
- **8-Frame History**: Smooth motion visualization
- **Alpha Blending**: Gradual fade-out effect
- **Real-time Updates**: Trails follow all 33 body landmarks

### 4. üìä 3D Visualization System

```python
# 3D matplotlib setup
fig = plt.figure(figsize=(8, 6))
ax = fig.add_subplot(111, projection='3d')

# Real-time 3D pose rendering
for i, j in POSE_CONNECTIONS:
    x_vals, y_vals, z_vals = zip(clone_landmarks_3d[i], clone_landmarks_3d[j])
    ax.plot(x_vals, y_vals, z_vals, color=line_color, linewidth=3)
```

**3D Features:**
- **Real-time Updates**: Synchronized with 2D view
- **Skeletal Connections**: 14 major bone connections
- **Color Synchronization**: Matches 2D neon effects
- **Optimized Rendering**: Updates every 6 frames for performance

## üíª Code Structure & Architecture

### üìÅ Project Files
```
acting clone/
‚îú‚îÄ‚îÄ app.py          # Main application file (fully functional)
‚îî‚îÄ‚îÄ readme.md       # This comprehensive documentation
```

### üèóÔ∏è Core Components

#### 1. **Initialization & Setup**
```python
# MediaPipe pose detector configuration
mp_pose = mp.solutions.pose
pose = mp_pose.Pose(
    static_image_mode=False,      # Video stream mode
    model_complexity=0,           # Fastest model for real-time
    smooth_landmarks=True,        # Temporal smoothing
    min_detection_confidence=0.5, # Detection threshold
    min_tracking_confidence=0.5   # Tracking threshold
)

# Camera setup with optimal resolution
cap = cv2.VideoCapture(0)
cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
```

#### 2. **Skeletal Connection Map**
```python
# 14 major skeletal connections for realistic human structure
POSE_CONNECTIONS = [
    (11, 12),  # Shoulders
    (11, 13), (13, 15),  # Left arm
    (12, 14), (14, 16),  # Right arm
    (11, 23), (12, 24),  # Torso
    (23, 24),  # Hips
    (23, 25), (25, 27),  # Left leg
    (24, 26), (26, 28),  # Right leg
    (27, 31), (28, 32)   # Feet
]
```

#### 3. **Visual Effects Functions**

**üé® Color Generation**
```python
def get_gradient_color(t):
    """Generate time-based HSV to RGB color gradients"""
    hue = (t * 120) % 360  # 120 degrees per second cycle
    # Full HSV to RGB conversion with smooth transitions
```

**‚ú® Glow Rendering**
```python
def draw_smooth_line(img, pt1, pt2, color, thickness):
    """Create glowing line effects with dual-layer rendering"""
    
def draw_smooth_circle(img, center, radius, color):
    """Draw glowing joint markers with white centers"""
```

#### 4. **Main Processing Loop Architecture**

```python
while cap.isOpened():
    # 1. Frame Capture & Preprocessing
    ret, frame = cap.read()
    frame = cv2.flip(frame, 1)  # Mirror for natural interaction
    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    
    # 2. Pose Detection
    results = pose.process(frame_rgb)
    
    # 3. Visual Effects Generation
    current_time = time.time()
    gradient_color = get_gradient_color(wave_time)
    pulse_intensity = 0.8 + 0.2 * math.sin(wave_time * 6)
    
    # 4. Clone Rendering (if pose detected)
    if results.pose_landmarks:
        # Mirror transformation
        # Glow effects application
        # Trail effects processing
        # 3D visualization update
    
    # 5. Fallback State (no pose detected)
    else:
        # Scanning animation display
    
    # 6. Performance Monitoring
    # FPS calculation and display
    
    # 7. Display & Input Handling
    cv2.imshow("CLONE TRACKER", frame)
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break
```

### ‚ö° Performance Optimizations

#### üéØ **Smart Update Strategies**
```python
# 3D plot updates every 6 frames instead of every frame
if frame_count % 6 == 0:
    # Update 3D visualization
    
# FPS display updates every 30 frames
if frame_count % 30 == 0:
    # Calculate and display FPS
```

#### üöÄ **Efficient Rendering**
- **MediaPipe Model**: Complexity 0 (fastest) for real-time performance
- **Selective Updates**: 3D plot refreshes at 1/6 frame rate
- **Optimized Blending**: Hardware-accelerated `cv2.addWeighted()`
- **Memory Management**: Fixed-size trail buffer prevents memory leaks

#### üìä **Performance Metrics**
- **Target FPS**: 30-60 FPS (hardware dependent)
- **Processing Latency**: <50ms for pose detection
- **Memory Usage**: ~200MB total application footprint
- **CPU Usage**: 15-30% on modern multi-core processors

## ‚öôÔ∏è Configuration & Customization

### üéõÔ∏è **Visual Parameters**
```python
# Trail effect settings
max_trail_length = 8        # Number of trail frames (2-20 recommended)

# Glow intensity settings  
pulse_intensity = 0.8       # Base glow intensity (0.5-1.0)
thickness = 6               # Line thickness (3-10 recommended)

# Color cycling speed
hue = (t * 120) % 360      # 120 = degrees per second (60-180 optimal)
```

### üìπ **Camera Settings**
```python
# Resolution options (balance quality vs performance)
cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)   # 640x480 (recommended)
cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)  # 1280x720 (high quality)
                                          # 320x240 (low-end hardware)

# Camera selection (if multiple cameras)
cap = cv2.VideoCapture(0)  # 0=default, 1=external, 2=secondary, etc.
```

### üß† **MediaPipe Tuning**
```python
pose = mp_pose.Pose(
    model_complexity=0,              # 0=fastest, 1=balanced, 2=accurate
    min_detection_confidence=0.5,    # 0.1-0.9 (lower=more sensitive)
    min_tracking_confidence=0.5,     # 0.1-0.9 (higher=more stable)
    smooth_landmarks=True            # Temporal smoothing on/off
)
```

## üõ†Ô∏è Troubleshooting & Common Issues

### üö® **Camera Issues**

**Problem**: "Camera not found" or black screen
```python
# Solution: Try different camera indices
cap = cv2.VideoCapture(0)  # Try 0, 1, 2, etc.

# Check available cameras (Windows)
# Run in command prompt: 
# python -c "import cv2; print([i for i in range(10) if cv2.VideoCapture(i).read()[0]])"
```

**Problem**: Poor video quality or lag
```python
# Solution: Adjust resolution
cap.set(cv2.CAP_PROP_FRAME_WIDTH, 320)   # Lower resolution
cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 240)  # For better performance
```

### üéØ **Pose Detection Issues**

**Problem**: Poor or no pose detection
- ‚úÖ **Lighting**: Ensure bright, even lighting (avoid backlighting)
- ‚úÖ **Distance**: Stand 3-6 feet from camera for optimal detection
- ‚úÖ **Clothing**: Wear contrasting colors (avoid camouflage patterns)
- ‚úÖ **Background**: Use plain, uncluttered background
- ‚úÖ **Full Body**: Ensure your full body is visible in frame

**Problem**: Jittery or unstable tracking
```python
# Solution: Increase tracking confidence
pose = mp_pose.Pose(
    min_tracking_confidence=0.8,  # Increase from 0.5 to 0.8
    smooth_landmarks=True         # Enable smoothing
)
```

### ‚ö° **Performance Issues**

**Problem**: Low FPS or choppy performance
```python
# Solution 1: Reduce model complexity
pose = mp_pose.Pose(model_complexity=0)  # Use fastest model

# Solution 2: Lower resolution
cap.set(cv2.CAP_PROP_FRAME_WIDTH, 320)
cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 240)

# Solution 3: Reduce trail length
max_trail_length = 4  # Reduce from 8 to 4

# Solution 4: Less frequent 3D updates
if frame_count % 10 == 0:  # Update every 10 frames instead of 6
```

**Problem**: High CPU usage
- Close other applications
- Use dedicated GPU if available
- Reduce camera resolution
- Increase 3D update interval

### üñºÔ∏è **Display Issues**

**Problem**: 3D plot window not appearing
```python
# Solution: Check matplotlib backend
import matplotlib
matplotlib.use('TkAgg')  # or 'Qt5Agg'
import matplotlib.pyplot as plt
```

**Problem**: Windows not displaying properly
- Check display scaling settings
- Ensure sufficient screen resolution
- Try running in windowed mode

### üêõ **Common Error Messages**

**Error**: `ImportError: No module named 'cv2'`
```bash
# Solution: Install OpenCV
pip install opencv-python
# or for conda users:
conda install opencv
```

**Error**: `ImportError: No module named 'mediapipe'`
```bash
# Solution: Install MediaPipe
pip install mediapipe
# Note: Requires Python 3.7-3.11
```

**Error**: `AttributeError: module 'cv2' has no attribute 'CAP_PROP_FRAME_WIDTH'`
```bash
# Solution: Update OpenCV
pip install --upgrade opencv-python
```

## üé® Advanced Customization

### üåà **Custom Color Schemes**

```python
# Cyberpunk theme
def get_cyberpunk_color(t):
    colors = [(255, 0, 255), (0, 255, 255), (255, 255, 0)]  # Magenta, Cyan, Yellow
    return colors[int(t) % len(colors)]

# Matrix theme  
def get_matrix_color(t):
    return (0, 255, 0)  # Classic green

# Fire theme
def get_fire_color(t):
    intensity = 0.5 + 0.5 * math.sin(t * 4)
    return (int(255 * intensity), int(100 * intensity), 0)
```

### ‚ú® **Enhanced Effects**

```python
# Particle system for joints
def draw_particles(img, center, color):
    for i in range(5):
        offset_x = random.randint(-10, 10)
        offset_y = random.randint(-10, 10)
        particle_pos = (center[0] + offset_x, center[1] + offset_y)
        cv2.circle(img, particle_pos, 2, color, -1)

# Breathing effect for skeleton
def apply_breathing_effect(landmarks, time):
    breath_factor = 1.0 + 0.05 * math.sin(time * 2)
    return [(int(x * breath_factor), int(y * breath_factor)) for x, y in landmarks]
```

### üìä **Data Export Features**

```python
# Save pose data to file
def save_pose_data(landmarks, filename):
    with open(filename, 'a') as f:
        timestamp = time.time()
        f.write(f"{timestamp},{landmarks}\n")

# Record video with effects
fourcc = cv2.VideoWriter_fourcc(*'XVID')
out = cv2.VideoWriter('clone_recording.avi', fourcc, 20.0, (640, 480))
```

## üöÄ Future Enhancement Ideas

### üéØ **Planned Features**
- **Multi-person Tracking**: Support for multiple people simultaneously
- **Gesture Recognition**: Detect specific poses and gestures
- **Recording System**: Save sessions as video files
- **Custom Backgrounds**: Green screen and virtual backgrounds
- **Sound Integration**: Audio-reactive visual effects
- **VR/AR Export**: Export pose data for VR applications

### üîß **Technical Improvements**
- **GPU Acceleration**: CUDA support for faster processing
- **Model Optimization**: Custom trained models for specific use cases
- **Network Streaming**: Stream pose data over network
- **Mobile Support**: Android/iOS compatibility
- **Web Version**: Browser-based implementation

## üìö Educational Value

### üéì **Learning Opportunities**
This project demonstrates:
- **Computer Vision**: Real-time image processing and analysis
- **Machine Learning**: Pre-trained model integration (MediaPipe)
- **Graphics Programming**: 2D/3D rendering and visual effects
- **Performance Optimization**: Real-time application development
- **User Interface**: Interactive application design

### üî¨ **Research Applications**
- **Motion Analysis**: Biomechanics and sports science
- **Rehabilitation**: Physical therapy progress tracking
- **Animation**: Motion capture for 3D animation
- **Fitness**: Exercise form analysis and correction
- **Accessibility**: Gesture-based computer interaction

## üìÑ License & Credits

### üë®‚Äçüíª **Project Creator**
**Shlok Sathe**
- GitHub: [@shloksathe18-dotcom](https://github.com/shloksathe18-dotcom)
- Project Repository: [Acting Clone Project](https://github.com/shloksathe18-dotcom/Acting-Clone-Project-)

### üìú **License**
This project is created by Shlok Sathe for educational and personal use.

### üôè **Technology Credits & Acknowledgments**
- **MediaPipe**: Google's pose estimation solution (Apache 2.0 License)
- **OpenCV**: Computer vision library (Apache 2.0 License)
- **NumPy**: Numerical computing library (BSD License)
- **Matplotlib**: Plotting library (PSF License)

### ü§ù **Contributing**
This project is maintained by Shlok Sathe. Feel free to:
- Visit the [GitHub repository](https://github.com/shloksathe18-dotcom/Acting-Clone-Project-)
- Submit bug reports and feature requests
- Create pull requests for improvements
- Share your custom modifications
- Suggest new visual effects or features

### üìû **Support**
For support and questions:
1. Check the troubleshooting section above
2. Visit the [GitHub repository](https://github.com/shloksathe18-dotcom/Acting-Clone-Project-) for issues
3. Verify all dependencies are installed correctly
4. Test with different camera settings
5. Check system compatibility requirements

---

**üé≠ Ready to see your digital clone in action? Run `python app.py` and step into the future of motion tracking!**

**Created with ‚ù§Ô∏è by [Shlok Sathe](https://github.com/shloksathe18-dotcom)**
